---
sidebar_position: 0
title: "Part II: Digital Twins, Autonomy & Vision-Language-Action"
---

# Part II: Digital Twins, Autonomy & Vision-Language-Action

This part explores advanced topics in AI for robotics, including simulation environments, perception systems, and autonomous decision making. It covers physics simulation with Gazebo, sensor simulation, Unity for human-robot interaction, NVIDIA Isaac Sim, Isaac ROS navigation, vision-language-action systems, speech recognition, language-to-action planning, autonomous decision making, and concludes with a comprehensive capstone project.

## Chapters in this Part:
- Chapter 11: [Gazebo: Physics & Simulation](./11_gazebo_physics_simulation.md)
- Chapter 12: [Sensors in Simulation](./12_sensors_in_simulation.md)
- Chapter 13: [Unity for Human-Robot Interaction](./13_unity_for_human_robot_interaction.md)
- Chapter 14: [NVIDIA Isaac Sim](./14_nvidia_isaac_sim.md)
- Chapter 15: [Isaac ROS & Navigation (Nav2)](./15_isaac_ros_navigation_nav2.md)
- Chapter 16: [What Is Vision-Language-Action (VLA)?](./16_what_is_vision_language_action.md)
- Chapter 17: [Voice to Text with Whisper](./17_voice_to_text_with_whisper.md)
- Chapter 18: [Language to Action Planning](./18_language_to_action_planning.md)
- Chapter 19: [Autonomous Decision Making](./19_autonomous_decision_making.md)
- Chapter 20: [Capstone: The Autonomous Humanoid](./20_capstone_the_autonomous_humanoid.md)

After completing this part, readers will have a comprehensive understanding of how to integrate all components into a complete autonomous robotics system.