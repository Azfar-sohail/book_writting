"use strict";(globalThis.webpackChunkai_native_textbook_platform=globalThis.webpackChunkai_native_textbook_platform||[]).push([[126],{8453(i,n,t){t.d(n,{R:()=>s,x:()=>r});var o=t(6540);const a={},e=o.createContext(a);function s(i){const n=o.useContext(e);return o.useMemo(function(){return"function"==typeof i?i(n):{...n,...i}},[n,i])}function r(i){let n;return n=i.disableParentContext?"function"==typeof i.components?i.components(a):i.components||a:s(i.components),o.createElement(e.Provider,{value:n},i.children)}},8876(i,n,t){t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>e,metadata:()=>r,toc:()=>l});var o=t(4848),a=t(8453);const e={sidebar_position:0,title:"Part II: Digital Twins, Autonomy & Vision-Language-Action"},s="Part II: Digital Twins, Autonomy & Vision-Language-Action",r={id:"part2/index",title:"Part II: Digital Twins, Autonomy & Vision-Language-Action",description:"This part explores advanced topics in AI for robotics, including simulation environments, perception systems, and autonomous decision making. It covers physics simulation with Gazebo, sensor simulation, Unity for human-robot interaction, NVIDIA Isaac Sim, Isaac ROS navigation, vision-language-action systems, speech recognition, language-to-action planning, autonomous decision making, and concludes with a comprehensive capstone project.",source:"@site/docs/part2/index.md",sourceDirName:"part2",slug:"/part2/",permalink:"/book-writting/part2/",draft:!1,unlisted:!1,editUrl:"https://github.com/Azfar-sohail/book-writting/tree/main/docs/part2/index.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{sidebar_position:0,title:"Part II: Digital Twins, Autonomy & Vision-Language-Action"},sidebar:"tutorialSidebar",previous:{title:"Chapter 10: URDF & Robot Description",permalink:"/book-writting/part1/urdf_robot_description"},next:{title:"Chapter 11: Gazebo: Physics & Simulation",permalink:"/book-writting/part2/gazebo_physics_simulation"}},c={},l=[{value:"Chapters in this Part:",id:"chapters-in-this-part",level:2}];function h(i){const n={a:"a",h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,a.R)(),...i.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"part-ii-digital-twins-autonomy--vision-language-action",children:"Part II: Digital Twins, Autonomy & Vision-Language-Action"}),"\n",(0,o.jsx)(n.p,{children:"This part explores advanced topics in AI for robotics, including simulation environments, perception systems, and autonomous decision making. It covers physics simulation with Gazebo, sensor simulation, Unity for human-robot interaction, NVIDIA Isaac Sim, Isaac ROS navigation, vision-language-action systems, speech recognition, language-to-action planning, autonomous decision making, and concludes with a comprehensive capstone project."}),"\n",(0,o.jsx)(n.h2,{id:"chapters-in-this-part",children:"Chapters in this Part:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Chapter 11: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/gazebo_physics_simulation",children:"Gazebo: Physics & Simulation"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 12: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/sensors_in_simulation",children:"Sensors in Simulation"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 13: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/unity_for_human_robot_interaction",children:"Unity for Human-Robot Interaction"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 14: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/nvidia_isaac_sim",children:"NVIDIA Isaac Sim"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 15: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/isaac_ros_navigation_nav2",children:"Isaac ROS & Navigation (Nav2)"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 16: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/what_is_vision_language_action",children:"What Is Vision-Language-Action (VLA)?"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 17: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/voice_to_text_with_whisper",children:"Voice to Text with Whisper"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 18: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/language_to_action_planning",children:"Language to Action Planning"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 19: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/autonomous_decision_making",children:"Autonomous Decision Making"})]}),"\n",(0,o.jsxs)(n.li,{children:["Chapter 20: ",(0,o.jsx)(n.a,{href:"/book-writting/part2/capstone_the_autonomous_humanoid",children:"Capstone: The Autonomous Humanoid"})]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"After completing this part, readers will have a comprehensive understanding of how to integrate all components into a complete autonomous robotics system."})]})}function p(i={}){const{wrapper:n}={...(0,a.R)(),...i.components};return n?(0,o.jsx)(n,{...i,children:(0,o.jsx)(h,{...i})}):h(i)}}}]);