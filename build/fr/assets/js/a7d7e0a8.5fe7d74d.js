"use strict";(globalThis.webpackChunkai_native_textbook_platform=globalThis.webpackChunkai_native_textbook_platform||[]).push([[84],{1438(n,e,i){i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var t=i(4848),s=i(8453);const a={sidebar_position:19,title:"Chapter 19: Autonomous Decision Making"},r="Chapter 19: Autonomous Decision Making",o={id:"part2/autonomous_decision_making",title:"Chapter 19: Autonomous Decision Making",description:"Introduction",source:"@site/docs/part2/19_autonomous_decision_making.md",sourceDirName:"part2",slug:"/part2/autonomous_decision_making",permalink:"/ai-native-textbook-platform/fr/docs/part2/autonomous_decision_making",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-humanoid-robots/tree/main/packages/create-docusaurus/templates/shared/docs/part2/19_autonomous_decision_making.md",tags:[],version:"current",sidebarPosition:19,frontMatter:{sidebar_position:19,title:"Chapter 19: Autonomous Decision Making"},sidebar:"tutorialSidebar",previous:{title:"Chapter 18: Language to Action Planning",permalink:"/ai-native-textbook-platform/fr/docs/part2/language_to_action_planning"},next:{title:"Chapter 20: Capstone: The Autonomous Humanoid",permalink:"/ai-native-textbook-platform/fr/docs/part2/capstone_the_autonomous_humanoid"}},c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Decision-Making Architectures",id:"decision-making-architectures",level:3},{value:"Planning and Reasoning",id:"planning-and-reasoning",level:3},{value:"Uncertainty Handling",id:"uncertainty-handling",level:3},{value:"Learning-Based Decision Making",id:"learning-based-decision-making",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Example 1: Behavior-Based Architecture",id:"example-1-behavior-based-architecture",level:3},{value:"Example 2: Decision Tree for Task Selection",id:"example-2-decision-tree-for-task-selection",level:3},{value:"Diagram Placeholders",id:"diagram-placeholders",level:2},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function d(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"chapter-19-autonomous-decision-making",children:"Chapter 19: Autonomous Decision Making"}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"Autonomous decision making is the cornerstone of intelligent robotics, enabling robots to operate independently in complex, dynamic environments. This chapter explores the principles, algorithms, and architectures for autonomous decision-making in robotics systems."}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Understand the fundamentals of autonomous decision making in robotics"}),"\n",(0,t.jsx)(e.li,{children:"Learn about different decision-making architectures and approaches"}),"\n",(0,t.jsx)(e.li,{children:"Explore planning algorithms for autonomous systems"}),"\n",(0,t.jsx)(e.li,{children:"Implement decision-making systems for robotics applications"}),"\n",(0,t.jsx)(e.li,{children:"Recognize the challenges of autonomy in real-world environments"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,t.jsx)(e.h3,{id:"decision-making-architectures",children:"Decision-Making Architectures"}),"\n",(0,t.jsx)(e.p,{children:"Structures for autonomous decision making:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Reactive Systems"}),": Immediate response to environmental changes"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Deliberative Systems"}),": Planning and reasoning before action"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Hybrid Architectures"}),": Combining reactive and deliberative approaches"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Behavior-Based"}),": Multiple concurrent behaviors with arbitration"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Hierarchical"}),": Different levels of decision making"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"planning-and-reasoning",children:"Planning and Reasoning"}),"\n",(0,t.jsx)(e.p,{children:"Algorithms for autonomous planning:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Classical Planning"}),": STRIPS, PDDL-based planning"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Motion Planning"}),": Path planning and trajectory generation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Temporal Planning"}),": Planning with time constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Contingent Planning"}),": Planning with uncertainty"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Multi-Agent Planning"}),": Coordination with other agents"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"uncertainty-handling",children:"Uncertainty Handling"}),"\n",(0,t.jsx)(e.p,{children:"Managing uncertainty in autonomous systems:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Probabilistic Reasoning"}),": Using probability distributions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Bayesian Networks"}),": Modeling uncertain relationships"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Markov Decision Processes"}),": Sequential decision making under uncertainty"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Partially Observable MDPs"}),": Decision making with incomplete information"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Robust Planning"}),": Planning that handles uncertainty"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"learning-based-decision-making",children:"Learning-Based Decision Making"}),"\n",(0,t.jsx)(e.p,{children:"Adaptive decision systems:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Reinforcement Learning"}),": Learning through trial and error"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Imitation Learning"}),": Learning from expert demonstrations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Online Learning"}),": Adapting to changing environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Transfer Learning"}),": Applying knowledge to new situations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Meta-Learning"}),": Learning to learn quickly"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,t.jsx)(e.h3,{id:"example-1-behavior-based-architecture",children:"Example 1: Behavior-Based Architecture"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist\nimport math\n\nclass Behavior:\n    def __init__(self, name):\n        self.name = name\n        self.active = False\n\n    def update(self, sensor_data):\n        """Update behavior state and return motor commands"""\n        pass\n\n    def get_priority(self):\n        """Return behavior priority (higher is more important)"""\n        return 0\n\nclass AvoidObstaclesBehavior(Behavior):\n    def __init__(self):\n        super().__init__("avoid_obstacles")\n        self.safe_distance = 0.5\n\n    def update(self, sensor_data):\n        if sensor_data is None:\n            return Twist()\n\n        # Find minimum distance in front of robot\n        front_distances = sensor_data.ranges[300:360] + sensor_data.ranges[0:60]\n        min_distance = min(front_distances)\n\n        cmd = Twist()\n        if min_distance < self.safe_distance:\n            # Turn away from obstacle\n            cmd.angular.z = 0.5 if min_distance < 0.3 else 0.3\n            cmd.linear.x = 0.0\n        else:\n            # Move forward\n            cmd.linear.x = 0.2\n\n        return cmd\n\n    def get_priority(self):\n        return 100 if min(sensor_data.ranges[300:60] if sensor_data else [float(\'inf\')]) < 0.5 else 10\n\nclass GoToGoalBehavior(Behavior):\n    def __init__(self):\n        super().__init__("go_to_goal")\n        self.goal_x = 5.0\n        self.goal_y = 5.0\n\n    def update(self, sensor_data):\n        # This would typically use robot\'s current position\n        # For simplicity, we\'ll return a basic forward command\n        cmd = Twist()\n        cmd.linear.x = 0.3\n        cmd.angular.z = 0.1\n        return cmd\n\n    def get_priority(self):\n        return 50\n\nclass AutonomousDecisionMaker(Node):\n    def __init__(self):\n        super().__init__(\'autonomous_decision_maker\')\n\n        # Initialize behaviors\n        self.behaviors = [\n            AvoidObstaclesBehavior(),\n            GoToGoalBehavior()\n        ]\n\n        # Publishers and subscribers\n        self.cmd_pub = self.create_publisher(Twist, \'cmd_vel\', 10)\n        self.scan_sub = self.create_subscription(\n            LaserScan, \'scan\', self.scan_callback, 10)\n\n        # Timer for decision making\n        self.timer = self.create_timer(0.1, self.make_decision)\n\n        self.current_scan = None\n\n    def scan_callback(self, msg):\n        self.current_scan = msg\n\n    def make_decision(self):\n        # Get all active behaviors\n        active_behaviors = [b for b in self.behaviors if b.get_priority() > 0]\n\n        if not active_behaviors:\n            # No active behaviors, stop robot\n            cmd = Twist()\n        else:\n            # Select behavior with highest priority\n            selected_behavior = max(active_behaviors, key=lambda b: b.get_priority())\n            cmd = selected_behavior.update(self.current_scan)\n\n        # Publish command\n        self.cmd_pub.publish(cmd)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    decision_maker = AutonomousDecisionMaker()\n    rclpy.spin(decision_maker)\n    decision_maker.destroy_node()\n    rclpy.shutdown()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"example-2-decision-tree-for-task-selection",children:"Example 2: Decision Tree for Task Selection"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'from enum import Enum\nfrom dataclasses import dataclass\nfrom typing import Dict, Any, Optional\nimport random\n\nclass TaskType(Enum):\n    NAVIGATION = "navigation"\n    MANIPULATION = "manipulation"\n    INSPECTION = "inspection"\n    CHARGING = "charging"\n\n@dataclass\nclass RobotState:\n    battery_level: float\n    current_task: Optional[TaskType]\n    location: str\n    objects_detected: list\n    time_since_last_task: int\n\nclass DecisionTree:\n    def __init__(self):\n        self.tasks = {\n            TaskType.NAVIGATION: self.execute_navigation,\n            TaskType.MANIPULATION: self.execute_manipulation,\n            TaskType.INSPECTION: self.execute_inspection,\n            TaskType.CHARGING: self.execute_charging\n        }\n\n    def select_task(self, state: RobotState) -> TaskType:\n        """Decision tree for task selection"""\n        # Priority 1: Battery level\n        if state.battery_level < 0.2:\n            return TaskType.CHARGING\n\n        # Priority 2: Emergency situations\n        if "obstacle" in state.objects_detected:\n            return TaskType.NAVIGATION\n\n        # Priority 3: Task-based decisions\n        if state.current_task == TaskType.MANIPULATION:\n            if state.objects_detected:\n                return TaskType.MANIPULATION\n            else:\n                return TaskType.NAVIGATION  # Navigate to find objects\n\n        # Priority 4: Routine tasks\n        if state.time_since_last_task > 3600:  # 1 hour\n            return TaskType.INSPECTION\n\n        # Default: Continue with current task or navigate\n        return state.current_task or TaskType.NAVIGATION\n\n    def execute_navigation(self, state: RobotState) -> Dict[str, Any]:\n        """Execute navigation task"""\n        return {\n            "action": "navigate",\n            "target_location": self.get_next_waypoint(state.location),\n            "priority": 1\n        }\n\n    def execute_manipulation(self, state: RobotState) -> Dict[str, Any]:\n        """Execute manipulation task"""\n        if state.objects_detected:\n            target_object = state.objects_detected[0]\n            return {\n                "action": "manipulate",\n                "target_object": target_object,\n                "priority": 2\n            }\n        return {"action": "idle", "priority": 0}\n\n    def execute_inspection(self, state: RobotState) -> Dict[str, Any]:\n        """Execute inspection task"""\n        return {\n            "action": "inspect",\n            "location": state.location,\n            "priority": 1\n        }\n\n    def execute_charging(self, state: RobotState) -> Dict[str, Any]:\n        """Execute charging task"""\n        return {\n            "action": "navigate",\n            "target_location": "charging_station",\n            "priority": 3\n        }\n\n    def get_next_waypoint(self, current_location: str) -> str:\n        """Simple waypoint selection"""\n        waypoints = ["entrance", "office", "kitchen", "storage"]\n        # Return next waypoint in sequence\n        try:\n            current_idx = waypoints.index(current_location)\n            return waypoints[(current_idx + 1) % len(waypoints)]\n        except ValueError:\n            return waypoints[0]  # Default to first waypoint\n\n# Example usage\ndecision_tree = DecisionTree()\nrobot_state = RobotState(\n    battery_level=0.8,\n    current_task=TaskType.MANIPULATION,\n    location="workshop",\n    objects_detected=["box", "tool"],\n    time_since_last_task=1800\n)\n\nselected_task = decision_tree.select_task(robot_state)\naction = decision_tree.tasks[selected_task](robot_state)\nprint(f"Selected task: {selected_task}")\nprint(f"Action: {action}")\n'})}),"\n",(0,t.jsx)(e.h2,{id:"diagram-placeholders",children:"Diagram Placeholders"}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.em,{children:"Diagram showing autonomous decision-making architecture"})}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.em,{children:"Hierarchy of planning and decision-making levels"})}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Autonomous decision making enables robots to operate independently in complex environments. Successful autonomous systems combine reactive behaviors, deliberative planning, and adaptive learning to handle uncertainty and changing conditions."}),"\n",(0,t.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Implement a decision-making system for a specific robot application."}),"\n",(0,t.jsx)(e.li,{children:"Compare different decision-making architectures for your use case."}),"\n",(0,t.jsx)(e.li,{children:"Design a system for handling conflicting objectives in decision making."}),"\n",(0,t.jsx)(e.li,{children:"Research and describe techniques for safe autonomous decision making."}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>r,x:()=>o});var t=i(6540);const s={},a=t.createContext(s);function r(n){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);