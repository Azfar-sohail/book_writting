"use strict";(globalThis.webpackChunkai_native_textbook_platform=globalThis.webpackChunkai_native_textbook_platform||[]).push([[664],{4317(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>t,toc:()=>c});var s=i(4848),r=i(8453);const a={sidebar_position:12,title:"Chapter 12: Sensors in Simulation"},o="Chapter 12: Sensors in Simulation",t={id:"part2/sensors_in_simulation",title:"Chapter 12: Sensors in Simulation",description:"Introduction",source:"@site/docs/part2/12_sensors_in_simulation.md",sourceDirName:"part2",slug:"/part2/sensors_in_simulation",permalink:"/ai-native-textbook-platform/ja/docs/part2/sensors_in_simulation",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-humanoid-robots/tree/main/packages/create-docusaurus/templates/shared/docs/part2/12_sensors_in_simulation.md",tags:[],version:"current",sidebarPosition:12,frontMatter:{sidebar_position:12,title:"Chapter 12: Sensors in Simulation"},sidebar:"tutorialSidebar",previous:{title:"Chapter 11: Gazebo: Physics & Simulation",permalink:"/ai-native-textbook-platform/ja/docs/part2/gazebo_physics_simulation"},next:{title:"Chapter 13: Unity for Human-Robot Interaction",permalink:"/ai-native-textbook-platform/ja/docs/part2/unity_for_human_robot_interaction"}},l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Camera Simulation",id:"camera-simulation",level:3},{value:"Range Sensors",id:"range-sensors",level:3},{value:"Inertial Sensors",id:"inertial-sensors",level:3},{value:"Force and Tactile Sensors",id:"force-and-tactile-sensors",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Example 1: Camera Sensor in URDF",id:"example-1-camera-sensor-in-urdf",level:3},{value:"Example 2: LIDAR Sensor Configuration",id:"example-2-lidar-sensor-configuration",level:3},{value:"Diagram Placeholders",id:"diagram-placeholders",level:2},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"chapter-12-sensors-in-simulation",children:"Chapter 12: Sensors in Simulation"}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(n.p,{children:"Accurate sensor simulation is crucial for developing and testing robotics algorithms. This chapter explores how various sensor types are simulated in Gazebo and other simulation environments, including cameras, LIDAR, IMU, and other sensor modalities."}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Understand different types of sensors used in robotics"}),"\n",(0,s.jsx)(n.li,{children:"Learn how sensors are simulated in Gazebo"}),"\n",(0,s.jsx)(n.li,{children:"Explore sensor noise modeling and realistic simulation"}),"\n",(0,s.jsx)(n.li,{children:"Implement sensor plugins for custom sensor types"}),"\n",(0,s.jsx)(n.li,{children:"Recognize the importance of sensor accuracy in simulation"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,s.jsx)(n.h3,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,s.jsx)(n.p,{children:"Simulating visual sensors with realistic properties:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"RGB Cameras"}),": Color image simulation with realistic distortion"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Depth Cameras"}),": Depth information with noise modeling"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stereo Cameras"}),": Two-camera systems for 3D reconstruction"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Wide-Angle/Fisheye"}),": Specialized cameras with distortion models"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sensor Parameters"}),": Resolution, field of view, focal length"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"range-sensors",children:"Range Sensors"}),"\n",(0,s.jsx)(n.p,{children:"Simulating distance measurement sensors:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"LIDAR"}),": 2D and 3D light detection and ranging"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sonar"}),": Ultrasonic distance sensors"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"IR Sensors"}),": Infrared proximity sensors"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Ray Tracing"}),": Accurate distance calculation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Noise Modeling"}),": Realistic sensor noise and limitations"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"inertial-sensors",children:"Inertial Sensors"}),"\n",(0,s.jsx)(n.p,{children:"Simulating motion and orientation sensors:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"IMU (Inertial Measurement Unit)"}),": Acceleration and angular velocity"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Gyroscope"}),": Angular velocity measurement"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Accelerometer"}),": Linear acceleration measurement"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Magnetometer"}),": Magnetic field measurement"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Fusion"}),": Combining multiple sensors for orientation"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"force-and-tactile-sensors",children:"Force and Tactile Sensors"}),"\n",(0,s.jsx)(n.p,{children:"Simulating contact and force measurement:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Force/Torque Sensors"}),": Measuring forces and torques at joints"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Tactile Sensors"}),": Contact detection and pressure sensing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Contact Modeling"}),": Accurate physical contact simulation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Grasp Detection"}),": Sensing object contact for manipulation"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,s.jsx)(n.h3,{id:"example-1-camera-sensor-in-urdf",children:"Example 1: Camera Sensor in URDF"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="camera_link">\n  <sensor type="camera" name="camera1">\n    <update_rate>30.0</update_rate>\n    <camera name="head">\n      <horizontal_fov>1.3962634</horizontal_fov>\n      <image>\n        <width>800</width>\n        <height>600</height>\n        <format>R8G8B8</format>\n      </image>\n      <clip>\n        <near>0.1</near>\n        <far>100</far>\n      </clip>\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.007</stddev>\n      </noise>\n    </camera>\n    <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n      <frame_name>camera_optical_frame</frame_name>\n      <topic_name>camera/image_raw</topic_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"example-2-lidar-sensor-configuration",children:"Example 2: LIDAR Sensor Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="lidar_link">\n  <sensor type="ray" name="lidar_sensor">\n    <pose>0 0 0 0 0 0</pose>\n    <visualize>true</visualize>\n    <update_rate>10</update_rate>\n    <ray>\n      <scan>\n        <horizontal>\n          <samples>720</samples>\n          <resolution>1</resolution>\n          <min_angle>-1.570796</min_angle>\n          <max_angle>1.570796</max_angle>\n        </horizontal>\n      </scan>\n      <range>\n        <min>0.10</min>\n        <max>30.0</max>\n        <resolution>0.01</resolution>\n      </range>\n    </ray>\n    <plugin name="lidar_controller" filename="libgazebo_ros_laser.so">\n      <topic_name>scan</topic_name>\n      <frame_name>lidar_link</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"diagram-placeholders",children:"Diagram Placeholders"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"Diagram showing the sensor simulation pipeline"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"Comparison of different sensor types in simulation"})}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"Accurate sensor simulation is essential for effective robotics development. Understanding how different sensor types are modeled in simulation helps bridge the gap between simulation and reality, enabling more robust algorithm development."}),"\n",(0,s.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Create a URDF model with multiple sensor types (camera, LIDAR, IMU)."}),"\n",(0,s.jsx)(n.li,{children:"Implement noise modeling for a simulated sensor."}),"\n",(0,s.jsx)(n.li,{children:"Compare the output of simulated vs real sensors for the same environment."}),"\n",(0,s.jsx)(n.li,{children:"Research and describe techniques for improving sensor simulation accuracy."}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>o,x:()=>t});var s=i(6540);const r={},a=s.createContext(r);function o(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);