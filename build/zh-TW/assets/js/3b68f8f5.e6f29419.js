"use strict";(globalThis.webpackChunkai_native_textbook_platform=globalThis.webpackChunkai_native_textbook_platform||[]).push([[671],{4342(e,n,a){a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>t,default:()=>_,frontMatter:()=>r,metadata:()=>o,toc:()=>l});var i=a(4848),s=a(8453);const r={sidebar_position:15,title:"Chapter 15: Isaac ROS & Navigation (Nav2)"},t="Chapter 15: Isaac ROS & Navigation (Nav2)",o={id:"part2/isaac_ros_navigation_nav2",title:"Chapter 15: Isaac ROS & Navigation (Nav2)",description:"Introduction",source:"@site/docs/part2/15_isaac_ros_navigation_nav2.md",sourceDirName:"part2",slug:"/part2/isaac_ros_navigation_nav2",permalink:"/ai-native-textbook-platform/zh-TW/docs/part2/isaac_ros_navigation_nav2",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-humanoid-robots/tree/main/packages/create-docusaurus/templates/shared/docs/part2/15_isaac_ros_navigation_nav2.md",tags:[],version:"current",sidebarPosition:15,frontMatter:{sidebar_position:15,title:"Chapter 15: Isaac ROS & Navigation (Nav2)"},sidebar:"tutorialSidebar",previous:{title:"Chapter 14: NVIDIA Isaac Sim",permalink:"/ai-native-textbook-platform/zh-TW/docs/part2/nvidia_isaac_sim"},next:{title:"Chapter 16: What Is Vision-Language-Action (VLA)?",permalink:"/ai-native-textbook-platform/zh-TW/docs/part2/what_is_vision_language_action"}},c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Isaac ROS Packages",id:"isaac-ros-packages",level:3},{value:"GPU Acceleration Benefits",id:"gpu-acceleration-benefits",level:3},{value:"Navigation2 Architecture",id:"navigation2-architecture",level:3},{value:"Perception-Action Integration",id:"perception-action-integration",level:3},{value:"Practical Examples",id:"practical-examples",level:2},{value:"Example 1: Isaac ROS Image Pipeline",id:"example-1-isaac-ros-image-pipeline",level:3},{value:"Example 2: Nav2 Configuration",id:"example-2-nav2-configuration",level:3},{value:"Diagram Placeholders",id:"diagram-placeholders",level:2},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"chapter-15-isaac-ros--navigation-nav2",children:"Chapter 15: Isaac ROS & Navigation (Nav2)"}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS brings GPU-accelerated perception and navigation capabilities to the ROS 2 ecosystem. This chapter explores Isaac ROS packages and their integration with the Navigation2 (Nav2) framework for advanced robotics applications."}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Understand the Isaac ROS package ecosystem"}),"\n",(0,i.jsx)(n.li,{children:"Learn about GPU-accelerated perception in robotics"}),"\n",(0,i.jsx)(n.li,{children:"Explore Navigation2 (Nav2) architecture and components"}),"\n",(0,i.jsx)(n.li,{children:"Implement GPU-accelerated navigation pipelines"}),"\n",(0,i.jsx)(n.li,{children:"Recognize the benefits of hardware acceleration in robotics"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,i.jsx)(n.h3,{id:"isaac-ros-packages",children:"Isaac ROS Packages"}),"\n",(0,i.jsx)(n.p,{children:"GPU-accelerated packages for robotics:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Image Pipeline"}),": GPU-accelerated image processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Stereo Disparity"}),": Real-time stereo vision processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Apriltag"}),": GPU-accelerated AprilTag detection"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS DNN Inference"}),": Deep learning inference acceleration"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Visual SLAM"}),": GPU-accelerated simultaneous localization and mapping"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"gpu-acceleration-benefits",children:"GPU Acceleration Benefits"}),"\n",(0,i.jsx)(n.p,{children:"Hardware acceleration advantages:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance"}),": Significant speedup for compute-intensive tasks"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-Time Processing"}),": Meeting strict timing requirements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Power Efficiency"}),": Better performance per watt on Jetson platforms"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scalability"}),": Handling multiple sensors and algorithms simultaneously"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Advanced Algorithms"}),": Enabling complex algorithms that would be too slow on CPU"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"navigation2-architecture",children:"Navigation2 Architecture"}),"\n",(0,i.jsx)(n.p,{children:"The Nav2 framework for robot navigation:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Behavior Trees"}),": Task planning and execution"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Costmaps"}),": Dynamic obstacle representation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Global Planner"}),": Path planning algorithms"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Local Planner"}),": Local trajectory generation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Controller"}),": Robot motion control"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"perception-action-integration",children:"Perception-Action Integration"}),"\n",(0,i.jsx)(n.p,{children:"Connecting perception with navigation:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor Fusion"}),": Combining multiple sensor inputs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"SLAM Integration"}),": Simultaneous localization and mapping"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Obstacle Detection"}),": Real-time obstacle identification"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Semantic Understanding"}),": Object recognition for navigation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dynamic Path Planning"}),": Adapting to changing environments"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"practical-examples",children:"Practical Examples"}),"\n",(0,i.jsx)(n.h3,{id:"example-1-isaac-ros-image-pipeline",children:"Example 1: Isaac ROS Image Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom isaac_ros_visual_slam_msgs.msg import IsaacROSVisualSlamResults\n\nclass IsaacROSImageProcessor(Node):\n    def __init__(self):\n        super().__init__('isaac_ros_image_processor')\n\n        # Subscribe to camera image\n        self.image_sub = self.create_subscription(\n            Image, '/camera/image_raw', self.image_callback, 10)\n\n        # Subscribe to Visual SLAM results\n        self.slam_sub = self.create_subscription(\n            IsaacROSVisualSlamResults, '/visual_slam/tracking/odometry',\n            self.slam_callback, 10)\n\n        # Publisher for processed results\n        self.result_pub = self.create_publisher(\n            Image, '/processed_image', 10)\n\n    def image_callback(self, msg):\n        # Process image using Isaac ROS accelerated algorithms\n        # This would typically involve GPU-accelerated operations\n        processed_image = self.accelerated_image_processing(msg)\n        self.result_pub.publish(processed_image)\n\n    def accelerated_image_processing(self, image_msg):\n        # Placeholder for GPU-accelerated image processing\n        # In practice, this would use Isaac ROS packages\n        return image_msg\n\ndef main(args=None):\n    rclpy.init(args=args)\n    processor = IsaacROSImageProcessor()\n    rclpy.spin(processor)\n    processor.destroy_node()\n    rclpy.shutdown()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"example-2-nav2-configuration",children:"Example 2: Nav2 Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# Navigation2 configuration for Isaac ROS integration\namcl:\n  ros__parameters:\n    use_sim_time: False\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_footprint"\n    beam_skip_distance: 0.5\n    beam_skip_error_threshold: 0.9\n    beam_skip_threshold: 0.3\n    do_beamskip: false\n    global_frame_id: "map"\n    lambda_short: 0.1\n    likelihood_max_dist: 2.0\n    set_initial_pose: true\n    initial_pose:\n      x: 0.0\n      y: 0.0\n      z: 0.0\n      yaw: 0.0\n    tf_broadcast: true\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.25\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.5\n    z_short: 0.05\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: False\n    global_frame: map\n    robot_base_frame: base_link\n    odom_topic: /odom\n    default_bt_xml_filename: "navigate_w_replanning_and_recovery.xml"\n    plugin_lib_names:\n      - nav2_compute_path_to_pose_action_bt_node\n      - nav2_follow_path_action_bt_node\n      - nav2_back_up_action_bt_node\n      - nav2_spin_action_bt_node\n      - nav2_wait_action_bt_node\n      - nav2_clear_costmap_service_bt_node\n      - nav2_is_stuck_condition_bt_node\n      - nav2_goal_reached_condition_bt_node\n      - nav2_goal_updated_condition_bt_node\n      - nav2_initial_pose_received_condition_bt_node\n      - nav2_reinitialize_global_localization_service_bt_node\n      - nav2_rate_controller_bt_node\n      - nav2_distance_controller_bt_node\n      - nav2_speed_controller_bt_node\n      - nav2_truncate_path_action_bt_node\n      - nav2_goal_updater_node_bt_node\n      - nav2_recovery_node_bt_node\n      - nav2_pipeline_sequence_bt_node\n      - nav2_round_robin_node_bt_node\n      - nav2_transform_available_condition_bt_node\n      - nav2_time_expired_condition_bt_node\n      - nav2_path_expiring_timer_condition\n      - nav2_distance_traveled_condition_bt_node\n'})}),"\n",(0,i.jsx)(n.h2,{id:"diagram-placeholders",children:"Diagram Placeholders"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"Diagram showing Isaac ROS package architecture"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"Architecture diagram of Navigation2 framework"})}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS brings GPU acceleration to robotics perception and navigation, while Navigation2 provides a robust framework for robot navigation. Together, they enable advanced robotics applications with improved performance and capabilities."}),"\n",(0,i.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Set up Isaac ROS packages on a compatible NVIDIA platform."}),"\n",(0,i.jsx)(n.li,{children:"Configure Navigation2 for a mobile robot with Isaac ROS sensors."}),"\n",(0,i.jsx)(n.li,{children:"Implement a perception-action pipeline using Isaac ROS."}),"\n",(0,i.jsx)(n.li,{children:"Compare performance between CPU and GPU-accelerated algorithms."}),"\n"]})]})}function _(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453(e,n,a){a.d(n,{R:()=>t,x:()=>o});var i=a(6540);const s={},r=i.createContext(s);function t(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);